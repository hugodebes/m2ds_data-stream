{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# River"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`River` is an open-source machine learning library for data streams. It is being developed by  **Télécom ParisTech**, **École Polytechique**, and the **University of Waikato**.\n",
    "\n",
    "In this lab we will use `River`. Visit the page of the [library](https://riverml.xyz/) and follow the [installation instructions](https://riverml.xyz/latest/getting-started/installation/).\n",
    "\n",
    "**Notice:** `River` requires `NumPy` and `Cython`\n",
    "Also, for this lab you will need: `scikit-learn`, `pandas`, and `matplotlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification in Data Streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this lab is to build a classifier capable of learning and making predictions in a datastream using the `River` library. In this lab we are comparing three datastream classifiers on Electricity dataset:\n",
    "- kNN\n",
    "- Hoeffding Tree\n",
    "- Batch-Incremental Ensemble Classifier (BIE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last of the three classifiers is not implemented yet. This is the task of this lab. You should implement the `learn_one` and `predict_one` methods in the `BatchClassifier` class. \n",
    "\n",
    "Tasks:\n",
    "1. Implement a tumbling window of size 100, creating and maintaining up to a maximum of 100 models. \n",
    "2. Build a batch `DecisionTreeClassifier` on each of the batches/windows.\n",
    "\n",
    "**Note:** The Decision Tree is a batch model that takes as input `np.array`. You can convert dictionaries (default data type in `River`) into `np.array` with the utility method `dict2numpy` available in `river.utils` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class BatchClassifier:\n",
    "\n",
    "    def __init__(self, window_size=100, max_models=100):\n",
    "        self.H = []\n",
    "        self.h = None\n",
    "        # TODO\n",
    "\n",
    "    def learn_one(self, x, y=None):\n",
    "        # TODO \n",
    "        # if not initialized ...\n",
    "            # Setup \n",
    "        # HINT: You can build a decision tree model on a set of data like this:\n",
    "        #       h = DecisionTreeClassifier()\n",
    "        #       h.fit(X_batch, y_batch)\n",
    "        #       self.H.append(h) # <-- and append it to the ensemble\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_one(self, x):\n",
    "        # TODO\n",
    "        # Be mindful of the case when the model is still empty and predictions are requested.\n",
    "        # The best practice is to return a default value.\n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we provide auxiliary functions and setup the evaluation. The `evaluate` method implements the test-then-train evaluation and tracks performance using `accuracy` and `kappa`. For each metric, two values are calculated: **prequential** (or rolling) indicates the performance of the model over a sliding window and **test-then-train** represents the performance of the model over *all* seen data from the stream. The method returns a dataframe with the results for the test calculated every `n_wait` samples (metrics are updated on every new sample). These results are used to plot performance later in the notebook.\n",
    "\n",
    "**Note:** You do not need to modify the code in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.tree import HoeffdingTreeClassifier\n",
    "from river.neighbors import KNNClassifier\n",
    "from river.stream import iter_pandas\n",
    "from river import metrics\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dataset = \"elec\"\n",
    "\n",
    "def print_progress(sample_id, acc, kappa):\n",
    "    print(f'Samples processed: {sample_id}')\n",
    "    print(acc)\n",
    "    print(kappa)\n",
    "\n",
    "def evaluate(stream, model, n_wait=1000, verbose=False):\n",
    "    acc = metrics.Accuracy()\n",
    "    acc_rolling = metrics.Rolling(metric=metrics.Accuracy(), window_size=n_wait)\n",
    "    kappa = metrics.CohenKappa()\n",
    "    kappa_rolling = metrics.Rolling(metric=metrics.CohenKappa(), window_size=n_wait)\n",
    "    raw_results = []\n",
    "    model_name = model.__class__.__name__\n",
    "    for i, (x, y) in enumerate(stream):\n",
    "        # Predict\n",
    "        y_pred = model.predict_one(x)\n",
    "        # Update metrics and results\n",
    "        acc.update(y_true=y, y_pred=y_pred)\n",
    "        acc_rolling.update(y_true=y, y_pred=y_pred)\n",
    "        kappa.update(y_true=y, y_pred=y_pred)\n",
    "        kappa_rolling.update(y_true=y, y_pred=y_pred)\n",
    "        if i % n_wait == 0 and i > 0:\n",
    "            if verbose:\n",
    "                print_progress(i, acc, kappa)\n",
    "            raw_results.append([model_name, i, acc.get(), acc_rolling.get(), kappa.get(), kappa_rolling.get()])\n",
    "        # Learn (train)\n",
    "        model.learn_one(x, y)\n",
    "    print_progress(i, acc, kappa)\n",
    "    return pd.DataFrame(raw_results, columns=['model', 'id', 'acc', 'acc_roll', 'kappa', 'kappa_roll'])\n",
    "\n",
    "# Load the data, will be transformed into a stream later\n",
    "df = pd.read_csv(\"./data/\"+dataset+\".csv\")\n",
    "label_col = df.columns[-1]\n",
    "feature_cols = list(df.columns)\n",
    "feature_cols.pop()\n",
    "X = df[feature_cols]\n",
    "Y = df[label_col]\n",
    "\n",
    "# Initialize models\n",
    "knn = KNNClassifier(n_neighbors=10, window_size=100)\n",
    "ht = HoeffdingTreeClassifier()\n",
    "bie = BatchClassifier(window_size=100, max_models=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra points\n",
    "\n",
    "Modify the evaluation to report training and testing time. Modify the plotting code accordingly to report processing time as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments\n",
    "\n",
    "Note that we convert the stream (`iter_pandas`) on each call to `evaluate`, this ensures that we are passing the stream properly initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results = evaluate(stream=iter_pandas(X=X, y=Y),\n",
    "                       model=knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_results = evaluate(stream=iter_pandas(X=X, y=Y),\n",
    "                      model=ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bie_results = evaluate(stream=iter_pandas(X=X, y=Y),\n",
    "                      model=bie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate plots\n",
    "\n",
    "The code below uses the raw results from the `evaluate` method to generate the plots for `accuracy` and `kappa` and generates a `pdf` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "dataset = \"elec\"\n",
    "\n",
    "df = pd.concat([knn_results, ht_results, bie_results])\n",
    "df.set_index('id', inplace=True)\n",
    "grouped = df.groupby('model')\n",
    "\n",
    "with PdfPages(f'results_{dataset}.pdf') as pdf:\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,5), sharey=True)\n",
    "    for metric, ax in zip(['acc', 'acc_roll'], axes.flatten()):\n",
    "        grouped[metric].plot(rot=45, title=metric, legend=True, ax=ax)\n",
    "        ax.legend([\"BIE\", \"HT\", r\"$k$NN\"], loc='best')\n",
    "        ax.grid(linestyle=':')\n",
    "    fig.suptitle(\"Accuracy on the %s dataset\" % dataset)\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()  # saves the current figure into a pdf page\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,5), sharey=True)\n",
    "    for metric, ax in zip(['kappa', 'kappa_roll'], axes.flatten()):\n",
    "        grouped[metric].plot(rot=45, title=metric, legend=True, ax=ax)\n",
    "        ax.legend([\"BIE\", \"HT\", r\"$k$NN\"], loc='best')\n",
    "        ax.grid(linestyle=':')\n",
    "    fig.suptitle(\"Kappa on the %s dataset\" % dataset)\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()  # saves the current figure into a pdf page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should submit:\n",
    "1. The Jupyter Notebook \n",
    "2. `html` version of notebook (go to: `File/Download as/HTML`), with visible outputs of your code\n",
    "\n",
    "in a compressed file (`.zip`, `.rar`, `tar.gz`...), and compressed file should be named: `firstname_lastname_lab2.zip`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
